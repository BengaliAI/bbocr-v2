{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jumpstart? How?\n",
    "\n",
    "- Create a folder called \"reconstruction\"\n",
    "- Create another folder called \"templates\" inside reconstruction\n",
    "- Populate with appropriate HTML files (kinda vague, but can't wrap everything in this notebook now. Just ask me aka Istiak Shihab). Also I will provide you a snapshot of my current directory structure. Just copy over the files needed. I guess.\n",
    "- Create another folder called \"img_src\" inside reconstruction\n",
    "- Create another folder called \"image\" inside reconstruction\n",
    "- Create another folder called \"html_output\" inside reconstruction\n",
    "- Now get out of reconstruction folder and Create YET another folder called \"image\". This is where you will keep your PNG images to run inference on.\n",
    "- Make sure the folder structure is like this: image/   best.pt    make-html.ipynb  environment.yml    reconstruction/...\n",
    "- Run this command `conda env create -f environment.yml`\n",
    "- You should be good to go? Hopefully.\n",
    "- Good Luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from apsisnet import ApsisNet\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.formatter import HTMLFormatter\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from pathlib import Path\n",
    "from shapely.geometry import box\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to YOLO Model. Currently it assumes that YOLO is in it's root directory, i.e: where the notebook is, and it's name is \"best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model_weight_path = \"best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Line Segmentation, Word Segmentation, OCR, and Layout Detection (YOLO) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/04/07 21:42:39] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\bbocr-env-v2\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/04/07 21:42:42] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\det\\\\ml\\\\Multilingual_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\rec\\\\arabic\\\\arabic_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\bbocr-env-v2\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\dict\\\\arabic_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ar', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "line = PaddleOCR(use_angle_cls=False, lang=\"en\", use_gpu=True)\n",
    "word = PaddleOCR(use_angle_cls=False, lang=\"ar\", use_gpu=True)\n",
    "# ocr = PaddleOCR(use_angle_cls=True, lang=\"en\")\n",
    "ocr = ApsisNet()\n",
    "model = YOLO(yolo_model_weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference helper functions for Line, Word segmentation and Word Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_segmentation(image):\n",
    "    result_line = line.ocr(image, rec=False, cls=False)[0]\n",
    "    return result_line\n",
    "\n",
    "\n",
    "def word_segmentation(image):\n",
    "    result_word = word.ocr(image, rec=False, cls=False)\n",
    "    return result_word\n",
    "\n",
    "def recognize_word(cropped_words):\n",
    "    # texts = ocr.ocr(image, det=False, rec=True, cls=True)[0][0][0]\n",
    "    texts = ocr.infer(cropped_words)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions for Inference run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padWordImage(img, pad_loc, pad_dim, pad_val):\n",
    "    \"\"\"\n",
    "    This function pads the image to the desired dimension\n",
    "    Args:\n",
    "    img: Image to be padded\n",
    "    pad_loc: Location of padding\n",
    "    pad_dim: Desired dimension of the padded image\n",
    "    pad_val: Value to be padded with\n",
    "    Returns:\n",
    "    img: Padded image\n",
    "    \"\"\"\n",
    "    if pad_loc == \"lr\":\n",
    "        h, w, d = img.shape\n",
    "        pad_width = pad_dim - w\n",
    "        pad = np.ones((h, pad_width, 3)) * pad_val\n",
    "        img = np.concatenate([img, pad], axis=1)\n",
    "    else:\n",
    "        h, w, d = img.shape\n",
    "        if h >= pad_dim:\n",
    "            return img\n",
    "        else:\n",
    "            pad_height = pad_dim - h\n",
    "            pad = np.ones((pad_height, w, 3)) * pad_val\n",
    "            img = np.concatenate([img, pad], axis=0)\n",
    "    return img.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctPadding(img, dim, pvalue=255):\n",
    "    \"\"\"\n",
    "    This function corrects the padding of the image\n",
    "    Args:\n",
    "    img: Image to be padded\n",
    "    dim: Desired dimension of the padded image\n",
    "    pvalue: Value to be padded with\n",
    "    Returns:\n",
    "    img: Padded image\n",
    "    mask: Mask of the padded image\n",
    "    \"\"\"\n",
    "    img_height, img_width = dim\n",
    "    mask = 0\n",
    "    h, w, d = img.shape\n",
    "    w_new = int(img_height * w / h)\n",
    "    img = cv2.resize(img, (w_new, img_height))\n",
    "    h, w, d = img.shape\n",
    "    if w > img_width:\n",
    "        h_new = int(img_width * h / w)\n",
    "        img = cv2.resize(img, (img_width, h_new))\n",
    "        img = padWordImage(img, pad_loc=\"tb\", pad_dim=img_height, pad_val=pvalue)\n",
    "        mask = img_width\n",
    "    elif w < img_width:\n",
    "        img = padWordImage(img, pad_loc=\"lr\", pad_dim=img_width, pad_val=pvalue)\n",
    "        mask = w\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_horizontal_dilation(boxes, image):\n",
    "    \"\"\"\n",
    "    This function performs horizontal dilation on the word boxes\n",
    "    Args:\n",
    "    boxes: Word boxes\n",
    "    image: Image\n",
    "    Returns:\n",
    "    image: Image with horizontal dilation\n",
    "    \"\"\"\n",
    "    crops = []\n",
    "    length = len(boxes)\n",
    "    for i in range(len(boxes)):\n",
    "\n",
    "        if i + 1 < length:\n",
    "            [[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]] = boxes[i]\n",
    "            [[x_min1, y_min1], [x_max1, y_min1], [x_max1, y_max1], [x_min1, y_max1]] = (\n",
    "                boxes[i + 1]\n",
    "            )\n",
    "\n",
    "            right_gap = x_min1 - x_max\n",
    "            if right_gap > 0:\n",
    "                x_max += right_gap // 2\n",
    "                x_min1 -= right_gap // 2\n",
    "\n",
    "                boxes[i][1][0], boxes[i][2][0] = x_max, x_max\n",
    "                boxes[i + 1][0][0], boxes[i + 1][3][0] = x_min1, x_min1\n",
    "\n",
    "                crop = image[int(y_min) : int(y_max), int(x_min) : int(x_max)]\n",
    "                h, w, d = crop.shape\n",
    "                if h != 0 and w != 0:\n",
    "                    crops.append(crop)\n",
    "\n",
    "    crop = image[\n",
    "        int(boxes[0][0][1]) : int(boxes[0][2][1]),\n",
    "        int(boxes[0][0][0]) : int(boxes[0][1][0]),\n",
    "    ]\n",
    "    h, w, d = crop.shape\n",
    "    if h != 0 and w != 0:\n",
    "        crops.append(crop)\n",
    "\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare HTMLGenerator Object. This Object takes care of fetching the template HTML file that is in \"reconstruction/templates/index.html\" file and populating this template using required class type layout and its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HtmlGenerator:\n",
    "    \"\"\"\n",
    "    This class generates the html file\n",
    "    \"\"\"\n",
    "    def __init__(self, filename=\"default\"):\n",
    "        \"\"\"\n",
    "        This function initializes the class\n",
    "        Args:\n",
    "        filename: Name of the html file\n",
    "        \"\"\"\n",
    "        with open(\"reconstruction/templates/index.html\", \"r\") as f:\n",
    "            index_template = f.read()\n",
    "\n",
    "        self.index_template = BeautifulSoup(index_template, \"html.parser\")\n",
    "        self.index_template_root_div = self.index_template.find(\"div\", {\"id\": \"root\"})\n",
    "        self.filename = filename\n",
    "\n",
    "    def read_html_template(self, template_name):\n",
    "        \"\"\"\n",
    "        This function reads the html template\n",
    "        Args:\n",
    "        template_name: Name of the template\n",
    "        Returns:\n",
    "        soup_template: Template\n",
    "        \"\"\"\n",
    "        with open(f\"reconstruction/templates/{template_name}.html\", \"r\") as f:\n",
    "            template = f.read()\n",
    "            soup_template = BeautifulSoup(template, \"html.parser\")\n",
    "            return soup_template\n",
    "\n",
    "    def get_styles(self, dict):\n",
    "        \"\"\"\n",
    "        This function gets the styles for the html elements\n",
    "        Args:\n",
    "        dict: Dictionary containing the styles\n",
    "        Returns:\n",
    "        styles: Styles for the html elements\n",
    "        \"\"\"\n",
    "        styles = f'top: {dict[\"top\"]}vh; left: {dict[\"left\"]}vw; height: {dict[\"elem_height\"]}vh; width: {dict[\"elem_width\"]}vw;'\n",
    "        return styles\n",
    "\n",
    "    def insert_paragraph(self, paragraph_info):\n",
    "        \"\"\"\n",
    "        This function inserts the paragraph into the html file\n",
    "        Args:\n",
    "        paragraph_info: Information about the paragraph\n",
    "        \"\"\"\n",
    "        paragraph_template = self.read_html_template(\"paragraph\")\n",
    "\n",
    "        p_tag = paragraph_template.find(\"p\")\n",
    "        text = paragraph_template.new_string(paragraph_info[\"text\"])\n",
    "        p_tag.append(text)\n",
    "\n",
    "        paragraph_div = paragraph_template.find(\"div\")\n",
    "        paragraph_div[\"style\"] = self.get_styles(paragraph_info)\n",
    "\n",
    "        self.index_template_root_div.append(paragraph_template)\n",
    "\n",
    "    def insert_text_box(self, text_box_info):\n",
    "        \"\"\"\n",
    "        This function inserts the text box into the html file\n",
    "        Args:\n",
    "        text_box_info: Information about the text box\n",
    "        \"\"\"\n",
    "        text_box_template = self.read_html_template(\"text_box\")\n",
    "\n",
    "        p_tag = text_box_template.find(\"p\")\n",
    "        text = text_box_template.new_string(text_box_info[\"text\"])\n",
    "        p_tag.append(text)\n",
    "\n",
    "        text_box_div = text_box_template.find(\"div\")\n",
    "        text_box_div[\"style\"] = self.get_styles(text_box_info)\n",
    "\n",
    "        self.index_template_root_div.append(text_box_template)\n",
    "\n",
    "    def insert_image(self, img_info):\n",
    "        \"\"\"\n",
    "        This function inserts the image into the html file\n",
    "        Args:\n",
    "        img_info: Information about the image\n",
    "        \"\"\"\n",
    "        image_template = self.read_html_template(\"image\")\n",
    "\n",
    "        img_div = image_template.find(\"div\")\n",
    "        img_div[\"style\"] = self.get_styles(img_info)\n",
    "\n",
    "        img_tag = image_template.new_tag(\"img\")\n",
    "        img_tag[\"src\"] = img_info[\"img_src\"]\n",
    "\n",
    "        img_style = \"width: 100%; height: 100%; object-fit: fill;\"\n",
    "        img_tag[\"style\"] = img_style\n",
    "\n",
    "        img_div.append(img_tag)\n",
    "\n",
    "        self.index_template_root_div.append(image_template)\n",
    "\n",
    "    def create_html_file(self):\n",
    "        \"\"\"\n",
    "        This function creates the html file\n",
    "        \"\"\"\n",
    "        global img_src_save_dir\n",
    "        html_path = Path(img_src_save_dir).parent\n",
    "        with open(html_path / f\"reconstruction/{self.filename}.html\", \"w\") as f:\n",
    "            f.write(\n",
    "                str(self.index_template.prettify(formatter=HTMLFormatter(indent=2)))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to initialize HTMLGenerator and passing element where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html(detected_elements_info, file_name):\n",
    "    \"\"\"\n",
    "    This function generates the html file\n",
    "    Args:\n",
    "    detected_elements_info: Information about the detected elements\n",
    "    file_name: Name of the file\n",
    "    \"\"\"\n",
    "    file_name, extension = file_name.split(\".\")\n",
    "\n",
    "    gen = HtmlGenerator(file_name)\n",
    "\n",
    "    for element_info in detected_elements_info:\n",
    "\n",
    "        if element_info[\"class\"] == \"paragraph\":\n",
    "            gen.insert_paragraph(element_info)\n",
    "\n",
    "        elif element_info[\"class\"] == \"text_box\":\n",
    "            gen.insert_text_box(element_info)\n",
    "\n",
    "        elif element_info[\"class\"] == \"image\":\n",
    "            gen.insert_image(element_info)\n",
    "\n",
    "    gen.create_html_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotate_crop_image(self, img: np.ndarray, points: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get a rotated and cropped image.\n",
    "\n",
    "        Args:\n",
    "            img (np.ndarray): Input image.\n",
    "            points (np.ndarray): np.ndarray of four points defining the region to crop.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Rotated and cropped image.\n",
    "        \"\"\"    # Use Green's theory to judge clockwise or counterclockwise\n",
    "        # author: biyanhua\n",
    "        d = 0.0\n",
    "        for index in range(-1, 3):\n",
    "            d += -0.5 * (points[index + 1][1] + points[index][1]) * (\n",
    "                        points[index + 1][0] - points[index][0])\n",
    "        if d < 0: # counterclockwise\n",
    "            tmp = np.array(points)\n",
    "            points[1], points[3] = tmp[3], tmp[1]\n",
    "\n",
    "        img_crop_width = int(\n",
    "            max(\n",
    "                np.linalg.norm(points[0] - points[1]),\n",
    "                np.linalg.norm(points[2] - points[3])))\n",
    "        img_crop_height = int(\n",
    "            max(\n",
    "                np.linalg.norm(points[0] - points[3]),\n",
    "                np.linalg.norm(points[1] - points[2])))\n",
    "        pts_std = np.float32([[0, 0], [img_crop_width, 0],\n",
    "                            [img_crop_width, img_crop_height],\n",
    "                            [0, img_crop_height]])\n",
    "        M = cv2.getPerspectiveTransform(points, pts_std)\n",
    "        dst_img = cv2.warpPerspective(\n",
    "            img,\n",
    "            M, (img_crop_width, img_crop_height),\n",
    "            borderMode=cv2.BORDER_REPLICATE,\n",
    "            flags=cv2.INTER_CUBIC)\n",
    "        dst_img_height, dst_img_width = dst_img.shape[0:2]\n",
    "        if dst_img_height * 1.0 / dst_img_width >= 1.5:\n",
    "            dst_img = np.rot90(dst_img)\n",
    "        return dst_img\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to get proper coordinate information and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_coordinates(xyxy_tensor, height, width):\n",
    "    \"\"\"\n",
    "    This function gets the normalized coordinates\n",
    "    Args:\n",
    "    xyxy_tensor: Tensor containing the coordinates\n",
    "    height: Height of the image\n",
    "    width: Width of the image\n",
    "    Returns:\n",
    "    coordinates: Normalized coordinates\n",
    "    \"\"\"\n",
    "    x_min = xyxy_tensor[0][0].item() / width\n",
    "    y_min = xyxy_tensor[0][1].item() / height\n",
    "    x_max = xyxy_tensor[0][2].item() / width\n",
    "    y_max = xyxy_tensor[0][3].item() / height\n",
    "\n",
    "    coordinates = [x_min, y_min, x_max, y_max]\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def get_original_coordinates(normalized_coordinates, image_width, image_height):\n",
    "    \"\"\"\n",
    "    This function gets the original coordinates\n",
    "    Args:\n",
    "    normalized_coordinates: Normalized coordinates\n",
    "    image_width: Width of the image\n",
    "    image_height: Height of the image\n",
    "    Returns:\n",
    "    orig_coordinates: Original coordinates\n",
    "    \"\"\"\n",
    "    orig_coordinates = [None] * 4\n",
    "\n",
    "    orig_coordinates[0] = math.floor(normalized_coordinates[0] * image_width)\n",
    "    orig_coordinates[1] = math.floor(normalized_coordinates[1] * image_height)\n",
    "    orig_coordinates[2] = math.ceil(normalized_coordinates[2] * image_width)\n",
    "    orig_coordinates[3] = math.ceil(normalized_coordinates[3] * image_height)\n",
    "\n",
    "    return orig_coordinates\n",
    "\n",
    "\n",
    "def get_coordinates_from_segmentation(result_word):\n",
    "    \"\"\"\n",
    "    This function gets the coordinates from the segmentation\n",
    "    Args:\n",
    "    result_word: Result of the word segmentation\n",
    "    Returns:\n",
    "    words_xyxy: Coordinates of the words\n",
    "    \"\"\"\n",
    "    words_xyxy = []\n",
    "    if result_word != None:\n",
    "        for i in range(len(result_word)):\n",
    "            [[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]] = (\n",
    "                result_word[i]\n",
    "            )\n",
    "            words_xyxy.append([int(x_min), int(y_min), int(x_max), int(y_max)])\n",
    "\n",
    "    return words_xyxy\n",
    "\n",
    "def top_bottom_padding(cropped_text_region):\n",
    "    \"\"\"\n",
    "    This function adds top and bottom padding to the cropped text region\n",
    "    Args:\n",
    "    cropped_text_region: Cropped text region\n",
    "    Returns:\n",
    "    padded_image: Padded image\n",
    "    \"\"\"\n",
    "    h, w = cropped_text_region.shape[:2]\n",
    "    padded_height = int(h * 1.5)\n",
    "    padded_width = w\n",
    "\n",
    "    padded_image = np.ones((padded_height, padded_width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    top_padding = (h * 2 - h) // 2\n",
    "    bottom_padding = top_padding + h\n",
    "\n",
    "    padded_image[top_padding:bottom_padding, :] = cropped_text_region\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes care of all the inference, that is, Layout Detection at first (`res = model(image)[0]`), then line segmentation, word segmentation and finally returning all of them with appropriate coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotate_crop_image( img: np.ndarray, points: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get a rotated and cropped image.\n",
    "\n",
    "        Args:\n",
    "            img (np.ndarray): Input image.\n",
    "            points (np.ndarray): np.ndarray of four points defining the region to crop.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Rotated and cropped image.\n",
    "        \"\"\"    # Use Green's theory to judge clockwise or counterclockwise\n",
    "        # author: biyanhua\n",
    "        d = 0.0\n",
    "        for index in range(-1, 3):\n",
    "            d += -0.5 * (points[index + 1][1] + points[index][1]) * (\n",
    "                        points[index + 1][0] - points[index][0])\n",
    "        if d < 0: # counterclockwise\n",
    "            tmp = np.array(points)\n",
    "            points[1], points[3] = tmp[3], tmp[1]\n",
    "\n",
    "        img_crop_width = int(\n",
    "            max(\n",
    "                np.linalg.norm(points[0] - points[1]),\n",
    "                np.linalg.norm(points[2] - points[3])))\n",
    "        img_crop_height = int(\n",
    "            max(\n",
    "                np.linalg.norm(points[0] - points[3]),\n",
    "                np.linalg.norm(points[1] - points[2])))\n",
    "        pts_std = np.float32([[0, 0], [img_crop_width, 0],\n",
    "                            [img_crop_width, img_crop_height],\n",
    "                            [0, img_crop_height]])\n",
    "        M = cv2.getPerspectiveTransform(points, pts_std)\n",
    "        dst_img = cv2.warpPerspective(\n",
    "            img,\n",
    "            M, (img_crop_width, img_crop_height),\n",
    "            borderMode=cv2.BORDER_REPLICATE,\n",
    "            flags=cv2.INTER_CUBIC)\n",
    "        dst_img_height, dst_img_width = dst_img.shape[0:2]\n",
    "        if dst_img_height * 1.0 / dst_img_width >= 1.5:\n",
    "            dst_img = np.rot90(dst_img)\n",
    "        return dst_img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = {0: \"paragraph\", 1: \"text_box\", 2: \"image\", 3: \"table\"}\n",
    "\n",
    "def run_inference(image_path, file_name, img_src_save_directory):\n",
    "    \"\"\"\n",
    "    This function runs the inference\n",
    "    Args:\n",
    "    image_path: Path of the image\n",
    "    file_name: Name of the file\n",
    "    img_src_save_directory: Directory to save the image\n",
    "    Returns:\n",
    "    region_of_interests: Region of interests\n",
    "    \"\"\"\n",
    "    file_name, extension = file_name.split(\".\")\n",
    "    image = cv2.imread(image_path)\n",
    "    res = model(image)[0]\n",
    "    res.save(f\"reconstruction/image/{file_name}.{extension}\")\n",
    "    region_of_interests = []\n",
    "    for i in range(len(res.boxes)):\n",
    "        info_dict = {\n",
    "            \"class\": None,\n",
    "            \"coordinates\": None,\n",
    "            \"left\": None,\n",
    "            \"top\": None,\n",
    "            \"elem_height\": None,\n",
    "            \"elem_width\": None,\n",
    "            \"img_height\": None,\n",
    "            \"img_width\": None,\n",
    "            \"text\": None,\n",
    "            \"single-line\": False,\n",
    "            \"img_src\": None,\n",
    "        }\n",
    "        cls = res.boxes[i].cls.item()\n",
    "        img_height, img_width = res.boxes[i].orig_shape\n",
    "        normalized_coordinates = get_normalized_coordinates(\n",
    "            res.boxes[i].xyxy, img_height, img_width\n",
    "        )\n",
    "        if cls == 0:\n",
    "            info_dict[\"class\"] = names[0]\n",
    "        elif cls == 1:\n",
    "            info_dict[\"class\"] = names[1]\n",
    "        elif cls == 2:\n",
    "            info_dict[\"class\"] = names[2]\n",
    "        elif cls == 3:\n",
    "            info_dict[\"class\"] = names[3]\n",
    "        info_dict[\"coordinates\"] = normalized_coordinates\n",
    "        info_dict[\"left\"], info_dict[\"top\"] = (\n",
    "            normalized_coordinates[0] * 100,\n",
    "            normalized_coordinates[1] * 100,\n",
    "        )\n",
    "        info_dict[\"img_height\"], info_dict[\"img_width\"] = img_height, img_width\n",
    "        info_dict[\"elem_width\"] = (\n",
    "            normalized_coordinates[2] - normalized_coordinates[0]\n",
    "        ) * 100\n",
    "        info_dict[\"elem_height\"] = (\n",
    "            normalized_coordinates[3] - normalized_coordinates[1]\n",
    "        ) * 100\n",
    "        if info_dict[\"class\"] == \"paragraph\" or info_dict[\"class\"] == \"text_box\":\n",
    "            x_min, y_min, x_max, y_max = get_original_coordinates(\n",
    "                normalized_coordinates, info_dict[\"img_width\"], info_dict[\"img_height\"]\n",
    "            )\n",
    "            cropped_text_region = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            cropped_text_region = top_bottom_padding(cropped_text_region)\n",
    "            result_line = line_segmentation(cropped_text_region)\n",
    "            line_coordinates = get_coordinates_from_segmentation(result_line)\n",
    "            sorted_line_coordinates = sorted(line_coordinates, key=lambda x: x[1])\n",
    "            text = []\n",
    "            for i in range(len(sorted_line_coordinates)):\n",
    "                cropped_line_region = cropped_text_region[\n",
    "                    sorted_line_coordinates[i][1] : sorted_line_coordinates[i][3],\n",
    "                    sorted_line_coordinates[i][0] : sorted_line_coordinates[i][2],\n",
    "                ]\n",
    "                if len(sorted_line_coordinates) == 1:\n",
    "                    info_dict[\"single-line\"] = True\n",
    "                    info_dict[\"elem_height\"] *= 1.4\n",
    "                if len(cropped_line_region) != 0:\n",
    "                    result_word = word_segmentation(cropped_line_region)[0]\n",
    "                    if result_word != None:\n",
    "                        if len(result_word) != 0:\n",
    "                            # print(result_word.shape)\n",
    "                            # sorted_result_word = sorted(\n",
    "                            #     result_word[0], key=lambda x: x[0]\n",
    "                            # )\n",
    "                            # print(sorted_result_word)\n",
    "                            print(np.array(result_word).shape)\n",
    "                            if len(result_word) != 0:\n",
    "                                crops=[]\n",
    "                                for tmp_box in  result_word:\n",
    "                                    print(np.array(tmp_box).shape)\n",
    "                                    img_crop = get_rotate_crop_image(cropped_line_region,np.array(tmp_box,dtype=np.float32))\n",
    "                                    crops.append(img_crop)\n",
    "                                words = recognize_word(crops)\n",
    "                                print(words)\n",
    "                                text += words\n",
    "            text = \" \".join(text)\n",
    "            info_dict[\"text\"] = text\n",
    "        elif info_dict[\"class\"] == \"image\":\n",
    "            x_min, y_min, x_max, y_max = get_original_coordinates(\n",
    "                normalized_coordinates, info_dict[\"img_width\"], info_dict[\"img_height\"]\n",
    "            )\n",
    "            cropped_image_region = image[y_min:y_max, x_min:x_max]\n",
    "            src = f\"{img_src_save_directory}\\\\{file_name}_{i}.{extension}\"\n",
    "            info_dict[\"img_src\"] = src\n",
    "            cv2.imwrite(\n",
    "                f\"reconstruction/image/{file_name}_{i}.{extension}\",\n",
    "                cropped_image_region,\n",
    "            )\n",
    "        region_of_interests.append(info_dict)\n",
    "    discard_elements = []\n",
    "    for i, element in enumerate(region_of_interests):\n",
    "        bb1 = box(\n",
    "            element[\"coordinates\"][0],\n",
    "            element[\"coordinates\"][1],\n",
    "            element[\"coordinates\"][2],\n",
    "            element[\"coordinates\"][3],\n",
    "        )\n",
    "\n",
    "        for j, other_element in enumerate(region_of_interests):\n",
    "            if j > i:\n",
    "                bb2 = box(\n",
    "                    other_element[\"coordinates\"][0],\n",
    "                    other_element[\"coordinates\"][1],\n",
    "                    other_element[\"coordinates\"][2],\n",
    "                    other_element[\"coordinates\"][3],\n",
    "                )\n",
    "                intersection = bb1.intersection(bb2).area\n",
    "                if bb1.area < bb2.area:\n",
    "                    iou = intersection / bb1.area\n",
    "                    if iou > 0.5:\n",
    "                        if i not in discard_elements:\n",
    "                            discard_elements.append(i)\n",
    "                else:\n",
    "                    iou = intersection / bb2.area\n",
    "                    if iou > 0.5:\n",
    "                        if j not in discard_elements:\n",
    "                            discard_elements.append(j)\n",
    "    items_deleted = 0\n",
    "    for index in discard_elements:\n",
    "        del region_of_interests[index - items_deleted]\n",
    "        items_deleted += 1\n",
    "    return region_of_interests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a gigantic class, takes care of everything, that is, calling inference and passing it to HTML Geneation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(directory, img_src_save_dir):\n",
    "    \"\"\"\n",
    "    This function reconstructs the image\n",
    "    Args:\n",
    "    directory: Directory containing the images\n",
    "    img_src_save_dir: Directory to save the image\n",
    "    \"\"\"\n",
    "    directory = \"image/\"  # Replace with your test directory path\n",
    "    img_src_save_dir = \"image/\"  # Replace with your image source directory path\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, file_name)):\n",
    "\n",
    "            file_path = directory + \"/\" + file_name\n",
    "\n",
    "            print(\n",
    "                \"----------------------------------------------------------------------------\"\n",
    "            )\n",
    "            print(\"File name:\", file_name)\n",
    "\n",
    "            start_time = time.time()\n",
    "            roi = run_inference(\n",
    "                file_path, file_name, img_src_save_dir\n",
    "            )\n",
    "            print(\n",
    "                \"Execution Time for Layout Prediction and Text Recognition:\",\n",
    "                round(time.time() - start_time, 2),\n",
    "                \"seconds\",\n",
    "            )\n",
    "\n",
    "            start_time = time.time()\n",
    "            print(roi)\n",
    "            generate_html(roi, file_name)\n",
    "            print(\n",
    "                \"Execution Time for Reconstruction:\",\n",
    "                round(time.time() - start_time, 2),\n",
    "                \"seconds\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify this to your need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "File name: Prothom_Alo.png\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 512x960 6 paragraphs, 3 text_boxs, 4400.5ms\n",
      "Speed: 18.1ms preprocess, 4400.5ms inference, 69.1ms postprocess per image at shape (1, 3, 512, 960)\n",
      "(20, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['তারা', 'আন্দোলন', 'অন্যতম', 'দলগুলোর', 'তবে', 'মাঠপর্যা', \"'যাওয়ার\", 'ধর্মাভাত্তক', 'করতে', 'উপজেলা', 'ইতিমধ্যে', \"'কার্যকর\", ';নিয়েছে।', \"সিদ্ধান্ত'\", \"নির্বাচনেও'\", 'মতো', 'নির্বাচনের', 'সংসদ', 'ইইলামী', 'এইসিদ্ধান্ত:']\n",
      "(19, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['আন্দোলন', 'সরকারের', 'যেদলের', 'অংশ', 'আগের', 'স্থানীয়', 'অংশনানেন', 'নির্দেশনা', 'উপজেলা', 'ইসলামী', 'পরিষদের', 'ইইনিয়ন', 'যদিও', 'যাতে', 'দায়িত্বশীল', 'নির্বাচনে', ';নির্বাচনে', 'কেউ', 'পাঠিয়েছে।']\n",
      "(1, 4, 2)\n",
      "(4, 2)\n",
      "['নিয়েছিল।']\n",
      "(23, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['জামায়াতে', 'নেয়ান', 'জাতায়', 'জানয়াররর', 'না', 'নিশ্চয়তা', 'সরকারের', 'সঙ্গে', 'দলের', 'অন্যান্য', '।দদও', 'অংশ', 'পেয়ে', 'সংসদ', \"বিগত৭'\", 'নির্বাচনের', 'সষ্ঠ', 'অধীন', \"ইসলামীও'\", 'বিরোধী', 'বিএনপিসহ', 'নির্বাচনে', 'এই']\n",
      "(22, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['হিসেবে', 'জামায়াতের', 'অঘোষিতভাবে', 'যাচ্ছে', 'মাথায়', 'মাসের', 'বচার', 'অংশ', 'হতে', 'প্রথম', 'এর', 'স্বতন্ত্র', 'সে', 'ধাপের', 'পরিষদের', 'সরকারের', 'স্থানীয়', 'নির্বাচনে', 'নির্বাচন', 'উপজেলা', 'আগামী\"', 'প্রার্থীরা']\n",
      "(1, 4, 2)\n",
      "(4, 2)\n",
      "['।নচ্ছেন।']\n",
      "(21, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['দলের', 'বলছেন', 'নেতারা', 'জামায়াতের', \"প্রাতানাধত্ব'নে:\", 'তাদের', 'সংসদে', 'করেছে।', 'নিবন্ধন', 'র্তাদের', 'বিষয়ে', 'অংশগ্রহণের', 'করে', 'নির্বাচন', 'নংসদ', 'বাতিল', 'কামশন', 'নির্বাচন', 'নির্বাচনে', 'উপজেলা', 'বর্জন']\n",
      "(23, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['পড়েছে।', 'অবস্থায়', 'স্থানায়', 'ব্যাপারে', '।কারণে', 'এ', 'হয়ে', 'প্রয়োজন', 'দলের', 'এ', 'তারা', 'উপজেলা', 'এবারের', \"'দেখানোটা\", 'অস্তিত্ব', 'চলে।', 'সরকারের', \"নির্বাচনের'\", 'ববললেই', 'পর্যায়েও', \"নেই'\", 'প্রতিনিধিত্ব', 'বিভিন্ন']\n",
      "(19, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['ওভা', 'যশোর', 'সাংগঠানকভাব', 'করছেন', 'হাতমধ্যে', 'দেওয়া', 'জায়গায়', 'সেসব', 'আছে.', 'অবস্থায়', 'ভালো', 'দল', 'এলাকায়', 'যেসব', 'কেবল', \"'\", 'নিরাচন', 'হচ্ছে।', 'প্রাথা']\n",
      "(17, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['আলোর', 'প্রথম', 'বলে', 'শুরুকরেছেন', 'তক্ষাবা', 'জামায়াতের', 'তৎপরতা', 'নেতারা', 'দিনাজপর.', 'জানিয়েছেন', 'পর্যায়ের', 'উপজেলায়', 'গাইবান্ধাসহ', 'প্রতিনিধিরা', 'বিভিন্ন', 'নির্বাচনী', 'বিভিন্ন']\n",
      "(5, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['এমন', 'সম্ভাবনা', 'আছে,', 'উপজেলায়', 'প্রার্থী']\n",
      "(1, 4, 2)\n",
      "(4, 2)\n",
      "['৩০০৩২০২৪']\n",
      "(13, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['নেমেছেন', 'জামায়াতের', 'স্বতন্ত্র', 'সম্ভাব্য', 'উপজেলায়', 'বিভিন্ন', 'করছেন।', 'হিসেবে', 'প্রাথারা', 'মাঠে', 'ইতিমধ্যে', 'নির্বাচন', 'প্রার্থীরা']\n",
      "(20, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['বেরুদ্ধে', 'সিদ্ধান্ত', 'আন্দোলনের', 'সসলাম', 'করবেন', 'অমান্য', 'দলায়', 'বলেন', 'আলোকে', 'প্রথম', 'রহমান', 'যগ্ম', 'জ্যেষ্ঠ', 'তাঁরর', 'করে', 'আতাউর', 'নির্বাচন', 'মহাসচিব', 'যাঁরা', 'গাজী']\n",
      "(3, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['পর', 'পৃষ্ঠার', 'প্রথম']\n",
      "(19, 4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "['ব্যবস্থা', 'সিদ্ধান্ত', 'আলোকে', 'হবে।', 'নেওয়া', 'করবেন.', 'অমান্য', 'বলেন.', 'প্রথম', 'রহমান', 'আতাউর', 'বিরুদ্ধে', 'তাঁদের', 'করে', 'মহাসচিব', 'নির্বাচন', 'দলীয়', 'গাজী', 'যাঁরা']\n",
      "Execution Time for Layout Prediction and Text Recognition: 80.62 seconds\n",
      "[{'class': 'paragraph', 'coordinates': [0.0, 0.5739344059377735, 0.9791915552787686, 0.7207034810977611], 'left': 0.0, 'top': 57.39344059377734, 'elem_height': 14.67690751599876, 'elem_width': 97.91915552787685, 'img_height': 857, 'img_width': 1612, 'text': \"তারাআন্দোলনঅন্যতমদলগুলোরতবেমাঠপর্যা'যাওয়ারধর্মাভাত্তককরতেউপজেলাইতিমধ্যে'কার্যকর;নিয়েছে।সিদ্ধান্ত'নির্বাচনেও'মতোনির্বাচনেরসংসদইইলামীএইসিদ্ধান্ত:আন্দোলনসরকারেরযেদলেরঅংশআগেরস্থানীয়অংশনানেননির্দেশনাউপজেলাইসলামীপরিষদেরইইনিয়নযদিওযাতেদায়িত্বশীলনির্বাচনে;নির্বাচনেকেউপাঠিয়েছে।নিয়েছিল।\", 'single-line': False, 'img_src': None}, {'class': 'paragraph', 'coordinates': [0.0020750046663781255, 0.380426217683416, 0.9791695947386787, 0.5300436832245479], 'left': 0.20750046663781255, 'top': 38.0426217683416, 'elem_height': 14.961746554113187, 'elem_width': 97.70945900723007, 'img_height': 857, 'img_width': 1612, 'text': 'জামায়াতেনেয়ানজাতায়জানয়ারররনানিশ্চয়তাসরকারেরসঙ্গেদলেরঅন্যান্য।দদওঅংশপেয়েসংসদবিগত৭\\'নির্বাচনেরসষ্ঠঅধীনইসলামীও\\'বিরোধীবিএনপিসহনির্বাচনেএইহিসেবেজামায়াতেরঅঘোষিতভাবেযাচ্ছেমাথায়মাসেরবচারঅংশহতেপ্রথমএরস্বতন্ত্রসেধাপেরপরিষদেরসরকারেরস্থানীয়নির্বাচনেনির্বাচনউপজেলাআগামী\"প্রার্থীরা।নচ্ছেন।', 'single-line': False, 'img_src': None}, {'class': 'paragraph', 'coordinates': [0.0, 0.8022891103595391, 0.9776493195564516, 1.0], 'left': 0.0, 'top': 80.22891103595391, 'elem_height': 19.77108896404609, 'elem_width': 97.76493195564517, 'img_height': 857, 'img_width': 1612, 'text': \"দলেরবলছেননেতারাজামায়াতেরপ্রাতানাধত্ব'নে:তাদেরসংসদেকরেছে।নিবন্ধনর্তাদেরবিষয়েঅংশগ্রহণেরকরেনির্বাচননংসদবাতিলকামশননির্বাচননির্বাচনেউপজেলাবর্জনপড়েছে।অবস্থায়স্থানায়ব্যাপারে।কারণেএহয়েপ্রয়োজনদলেরএতারাউপজেলাএবারের'দেখানোটাঅস্তিত্বচলে।সরকারেরনির্বাচনের'ববললেইপর্যায়েওনেই'প্রতিনিধিত্ববিভিন্নওভাযশোরসাংগঠানকভাবকরছেনহাতমধ্যেদেওয়াজায়গায়সেসবআছে.অবস্থায়ভালোদলএলাকায়যেসবকেবল'নিরাচনহচ্ছে।প্রাথাআলোরপ্রথমবলেশুরুকরেছেনতক্ষাবাজামায়াতেরতৎপরতানেতারাদিনাজপর.জানিয়েছেনপর্যায়েরউপজেলায়গাইবান্ধাসহপ্রতিনিধিরাবিভিন্ননির্বাচনীবিভিন্ন\", 'single-line': False, 'img_src': None}, {'class': 'text_box', 'coordinates': [0.011057250257165497, 0.04867871528189269, 0.43431856141196884, 0.12469592812180937], 'left': 1.1057250257165496, 'top': 4.867871528189268, 'elem_height': 10.642409797588334, 'elem_width': 42.32613111548034, 'img_height': 857, 'img_width': 1612, 'text': 'এমনসম্ভাবনাআছে,উপজেলায়প্রার্থী', 'single-line': True, 'img_src': None}, {'class': 'text_box', 'coordinates': [0.002187879890129525, 0.19265707899558782, 0.09605827047570467, 0.23220524292704384], 'left': 0.2187879890129525, 'top': 19.26570789955878, 'elem_height': 5.536742950403842, 'elem_width': 9.387039058557514, 'img_height': 857, 'img_width': 1612, 'text': '৩০০৩২০২৪', 'single-line': True, 'img_src': None}, {'class': 'paragraph', 'coordinates': [0.0027384441484588546, 0.3176337189824606, 0.6132949942690563, 0.36504980953042954], 'left': 0.27384441484588545, 'top': 31.763371898246064, 'elem_height': 6.638252676715647, 'elem_width': 61.05565501205975, 'img_height': 857, 'img_width': 1612, 'text': 'নেমেছেনজামায়াতেরস্বতন্ত্রসম্ভাব্যউপজেলায়বিভিন্নকরছেন।হিসেবেপ্রাথারামাঠেইতিমধ্যেনির্বাচনপ্রার্থীরা', 'single-line': True, 'img_src': None}, {'class': 'paragraph', 'coordinates': [0.00023047130545670577, 0.7371660942513857, 0.8495830223518921, 0.7912156095026255], 'left': 0.023047130545670577, 'top': 73.71660942513857, 'elem_height': 7.566932135173572, 'elem_width': 84.93525510464353, 'img_height': 857, 'img_width': 1612, 'text': 'বেরুদ্ধেসিদ্ধান্তআন্দোলনেরসসলামকরবেনঅমান্যদলায়বলেনআলোকেপ্রথমরহমানযগ্মজ্যেষ্ঠতাঁররকরেআতাউরনির্বাচনমহাসচিবযাঁরাগাজী', 'single-line': True, 'img_src': None}, {'class': 'text_box', 'coordinates': [0.0021906376772423833, 0.2568822836236052, 0.09815690298530068, 0.29790237765050687], 'left': 0.21906376772423833, 'top': 25.688228362360523, 'elem_height': 5.742813163766232, 'elem_width': 9.59662653080583, 'img_height': 857, 'img_width': 1612, 'text': 'পরপৃষ্ঠারপ্রথম', 'single-line': True, 'img_src': None}]\n",
      "Execution Time for Reconstruction: 1.8 seconds\n"
     ]
    }
   ],
   "source": [
    "test_image_directory = \"image/\"\n",
    "img_src_save_dir = \"image/\"\n",
    "reconstruct(test_image_directory, img_src_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
