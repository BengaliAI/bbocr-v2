{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jumpstart? How?\n",
    "\n",
    "- Create a folder called \"reconstruction\"\n",
    "- Create another folder called \"templates\" inside reconstruction\n",
    "- Populate with appropriate HTML files (kinda vague, but can't wrap everything in this notebook now. Just ask me aka Istiak Shihab). Also I will provide you a snapshot of my current directory structure. Just copy over the files needed. I guess.\n",
    "- Create another folder called \"img_src\" inside reconstruction\n",
    "- Create another folder called \"image\" inside reconstruction\n",
    "- Create another folder called \"html_output\" inside reconstruction\n",
    "- Now get out of reconstruction folder and Create YET another folder called \"image\". This is where you will keep your PNG images to run inference on.\n",
    "- Make sure the folder structure is like this: image/   best.pt    make-html.ipynb  environment.yml    reconstruction/...\n",
    "- Run this command `conda env create -f environment.yml`\n",
    "- You should be good to go? Hopefully.\n",
    "- Good Luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.formatter import HTMLFormatter\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from pathlib import Path\n",
    "from shapely.geometry import box\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to YOLO Model. Currently it assumes that YOLO is in it's root directory, i.e: where the notebook is, and it's name is \"best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model_weight_path = \"best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Line Segmentation, Word Segmentation, OCR, and Layout Detection (YOLO) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/04/08 11:15:03] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\bbocr-env-v2\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/04/08 11:15:05] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\det\\\\ml\\\\Multilingual_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\rec\\\\arabic\\\\arabic_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\bbocr-env-v2\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\dict\\\\arabic_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ar', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/04/08 11:15:06] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\bbocr-env-v2\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\USER/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "line = PaddleOCR(use_angle_cls=False, lang=\"en\", use_gpu=True)\n",
    "word = PaddleOCR(use_angle_cls=False, lang=\"ar\", use_gpu=True)\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang=\"en\")\n",
    "model = YOLO(yolo_model_weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference helper functions for Line, Word segmentation and Word Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_segmentation(image):\n",
    "    result_line = line.ocr(image, rec=False, cls=False)[0]\n",
    "    return result_line\n",
    "\n",
    "\n",
    "def word_segmentation(image):\n",
    "    result_word = word.ocr(image, rec=False, cls=False)[0]\n",
    "    return result_word\n",
    "\n",
    "def recognize_word(image, result_word):\n",
    "    texts = ocr.ocr(image, det=False, rec=True, cls=True)[0][0][0]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions for Inference run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padWordImage(img, pad_loc, pad_dim, pad_val):\n",
    "    \"\"\"\n",
    "    This function pads the image to the desired dimension\n",
    "    Args:\n",
    "    img: Image to be padded\n",
    "    pad_loc: Location of padding\n",
    "    pad_dim: Desired dimension of the padded image\n",
    "    pad_val: Value to be padded with\n",
    "    Returns:\n",
    "    img: Padded image\n",
    "    \"\"\"\n",
    "    if pad_loc == \"lr\":\n",
    "        h, w, d = img.shape\n",
    "        pad_width = pad_dim - w\n",
    "        pad = np.ones((h, pad_width, 3)) * pad_val\n",
    "        img = np.concatenate([img, pad], axis=1)\n",
    "    else:\n",
    "        h, w, d = img.shape\n",
    "        if h >= pad_dim:\n",
    "            return img\n",
    "        else:\n",
    "            pad_height = pad_dim - h\n",
    "            pad = np.ones((pad_height, w, 3)) * pad_val\n",
    "            img = np.concatenate([img, pad], axis=0)\n",
    "    return img.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctPadding(img, dim, pvalue=255):\n",
    "    \"\"\"\n",
    "    This function corrects the padding of the image\n",
    "    Args:\n",
    "    img: Image to be padded\n",
    "    dim: Desired dimension of the padded image\n",
    "    pvalue: Value to be padded with\n",
    "    Returns:\n",
    "    img: Padded image\n",
    "    mask: Mask of the padded image\n",
    "    \"\"\"\n",
    "    img_height, img_width = dim\n",
    "    mask = 0\n",
    "    h, w, d = img.shape\n",
    "    w_new = int(img_height * w / h)\n",
    "    img = cv2.resize(img, (w_new, img_height))\n",
    "    h, w, d = img.shape\n",
    "    if w > img_width:\n",
    "        h_new = int(img_width * h / w)\n",
    "        img = cv2.resize(img, (img_width, h_new))\n",
    "        img = padWordImage(img, pad_loc=\"tb\", pad_dim=img_height, pad_val=pvalue)\n",
    "        mask = img_width\n",
    "    elif w < img_width:\n",
    "        img = padWordImage(img, pad_loc=\"lr\", pad_dim=img_width, pad_val=pvalue)\n",
    "        mask = w\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_horizontal_dilation(boxes, image):\n",
    "    \"\"\"\n",
    "    This function performs horizontal dilation on the word boxes\n",
    "    Args:\n",
    "    boxes: Word boxes\n",
    "    image: Image\n",
    "    Returns:\n",
    "    image: Image with horizontal dilation\n",
    "    \"\"\"\n",
    "    crops = []\n",
    "    length = len(boxes)\n",
    "    for i in range(len(boxes)):\n",
    "\n",
    "        if i + 1 < length:\n",
    "            [[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]] = boxes[i]\n",
    "            [[x_min1, y_min1], [x_max1, y_min1], [x_max1, y_max1], [x_min1, y_max1]] = (\n",
    "                boxes[i + 1]\n",
    "            )\n",
    "\n",
    "            right_gap = x_min1 - x_max\n",
    "            if right_gap > 0:\n",
    "                x_max += right_gap // 2\n",
    "                x_min1 -= right_gap // 2\n",
    "\n",
    "                boxes[i][1][0], boxes[i][2][0] = x_max, x_max\n",
    "                boxes[i + 1][0][0], boxes[i + 1][3][0] = x_min1, x_min1\n",
    "\n",
    "                crop = image[int(y_min) : int(y_max), int(x_min) : int(x_max)]\n",
    "                h, w, d = crop.shape\n",
    "                if h != 0 and w != 0:\n",
    "                    crops.append(crop)\n",
    "\n",
    "    crop = image[\n",
    "        int(boxes[0][0][1]) : int(boxes[0][2][1]),\n",
    "        int(boxes[0][0][0]) : int(boxes[0][1][0]),\n",
    "    ]\n",
    "    h, w, d = crop.shape\n",
    "    if h != 0 and w != 0:\n",
    "        crops.append(crop)\n",
    "\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare HTMLGenerator Object. This Object takes care of fetching the template HTML file that is in \"reconstruction/templates/index.html\" file and populating this template using required class type layout and its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HtmlGenerator:\n",
    "    \"\"\"\n",
    "    This class generates the html file\n",
    "    \"\"\"\n",
    "    def __init__(self, filename=\"default\"):\n",
    "        \"\"\"\n",
    "        This function initializes the class\n",
    "        Args:\n",
    "        filename: Name of the html file\n",
    "        \"\"\"\n",
    "        with open(\"reconstruction/templates/index.html\", \"r\") as f:\n",
    "            index_template = f.read()\n",
    "\n",
    "        self.index_template = BeautifulSoup(index_template, \"html.parser\")\n",
    "        self.index_template_root_div = self.index_template.find(\"div\", {\"id\": \"root\"})\n",
    "        self.filename = filename\n",
    "\n",
    "    def read_html_template(self, template_name):\n",
    "        \"\"\"\n",
    "        This function reads the html template\n",
    "        Args:\n",
    "        template_name: Name of the template\n",
    "        Returns:\n",
    "        soup_template: Template\n",
    "        \"\"\"\n",
    "        with open(f\"reconstruction/templates/{template_name}.html\", \"r\") as f:\n",
    "            template = f.read()\n",
    "            soup_template = BeautifulSoup(template, \"html.parser\")\n",
    "            return soup_template\n",
    "\n",
    "    def get_styles(self, dict):\n",
    "        \"\"\"\n",
    "        This function gets the styles for the html elements\n",
    "        Args:\n",
    "        dict: Dictionary containing the styles\n",
    "        Returns:\n",
    "        styles: Styles for the html elements\n",
    "        \"\"\"\n",
    "        styles = f'top: {dict[\"top\"]}vh; left: {dict[\"left\"]}vw; height: {dict[\"elem_height\"]}vh; width: {dict[\"elem_width\"]}vw;'\n",
    "        return styles\n",
    "\n",
    "    # def insert_paragraph(self, paragraph_info):\n",
    "    #     \"\"\"\n",
    "    #     This function inserts the paragraph into the html file\n",
    "    #     Args:\n",
    "    #     paragraph_info: Information about the paragraph\n",
    "    #     \"\"\"\n",
    "    #     paragraph_template = self.read_html_template(\"paragraph\")\n",
    "\n",
    "    #     p_tag = paragraph_template.find(\"p\")\n",
    "    #     text = paragraph_template.new_string(paragraph_info[\"text\"])\n",
    "    #     p_tag.append(text)\n",
    "\n",
    "    #     paragraph_div = paragraph_template.find(\"div\")\n",
    "    #     paragraph_div[\"style\"] = self.get_styles(paragraph_info)\n",
    "\n",
    "    #     self.index_template_root_div.append(paragraph_template)\n",
    "\n",
    "    def insert_paragraph(self, paragraph_info):\n",
    "        \"\"\"\n",
    "        This function inserts the paragraph into the html file\n",
    "        Args:\n",
    "        paragraph_info: Information about the paragraph\n",
    "        \"\"\"\n",
    "        paragraph_template = self.read_html_template(\"paragraph\")\n",
    "\n",
    "        p_tag = paragraph_template.find(\"p\")\n",
    "        text = paragraph_template.new_string(paragraph_info[\"text\"])\n",
    "        p_tag.append(text)\n",
    "\n",
    "        paragraph_div = paragraph_template.find(\"div\")\n",
    "        paragraph_div[\"style\"] = self.get_styles(paragraph_info)\n",
    "\n",
    "        # Include font size in style\n",
    "        paragraph_div[\"style\"] += f'font-size: {paragraph_info[\"font_size\"]}px;'\n",
    "\n",
    "        self.index_template_root_div.append(paragraph_template)\n",
    "\n",
    "    # def insert_text_box(self, text_box_info):\n",
    "    #     \"\"\"\n",
    "    #     This function inserts the text box into the html file\n",
    "    #     Args:\n",
    "    #     text_box_info: Information about the text box\n",
    "    #     \"\"\"\n",
    "    #     text_box_template = self.read_html_template(\"text_box\")\n",
    "\n",
    "    #     p_tag = text_box_template.find(\"p\")\n",
    "    #     text = text_box_template.new_string(text_box_info[\"text\"])\n",
    "    #     p_tag.append(text)\n",
    "\n",
    "    #     text_box_div = text_box_template.find(\"div\")\n",
    "    #     text_box_div[\"style\"] = self.get_styles(text_box_info)\n",
    "\n",
    "    #     self.index_template_root_div.append(text_box_template)\n",
    "\n",
    "    def insert_text_box(self, text_box_info):\n",
    "        \"\"\"\n",
    "        This function inserts the text box into the html file\n",
    "        Args:\n",
    "        text_box_info: Information about the text box\n",
    "        \"\"\"\n",
    "        text_box_template = self.read_html_template(\"text_box\")\n",
    "\n",
    "        p_tag = text_box_template.find(\"p\")\n",
    "        text = text_box_template.new_string(text_box_info[\"text\"])\n",
    "        p_tag.append(text)\n",
    "\n",
    "        text_box_div = text_box_template.find(\"div\")\n",
    "        text_box_div[\"style\"] = self.get_styles(text_box_info)\n",
    "\n",
    "        # Include font size in style\n",
    "        text_box_div[\"style\"] += f'font-size: {text_box_info[\"font_size\"]}px;'\n",
    "\n",
    "        self.index_template_root_div.append(text_box_template)\n",
    "\n",
    "    def insert_image(self, img_info):\n",
    "        \"\"\"\n",
    "        This function inserts the image into the html file\n",
    "        Args:\n",
    "        img_info: Information about the image\n",
    "        \"\"\"\n",
    "        image_template = self.read_html_template(\"image\")\n",
    "\n",
    "        img_div = image_template.find(\"div\")\n",
    "        img_div[\"style\"] = self.get_styles(img_info)\n",
    "\n",
    "        img_tag = image_template.new_tag(\"img\")\n",
    "        img_tag[\"src\"] = img_info[\"img_src\"]\n",
    "\n",
    "        img_style = \"width: 100%; height: 100%; object-fit: fill;\"\n",
    "        img_tag[\"style\"] = img_style\n",
    "\n",
    "        img_div.append(img_tag)\n",
    "\n",
    "        self.index_template_root_div.append(image_template)\n",
    "\n",
    "    def create_html_file(self):\n",
    "        \"\"\"\n",
    "        This function creates the html file\n",
    "        \"\"\"\n",
    "        global img_src_save_dir\n",
    "        html_path = Path(img_src_save_dir).parent\n",
    "        with open(html_path / f\"reconstruction/{self.filename}.html\", \"w\") as f:\n",
    "            f.write(\n",
    "                str(self.index_template.prettify(formatter=HTMLFormatter(indent=2)))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to initialize HTMLGenerator and passing element where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html(detected_elements_info, file_name):\n",
    "    \"\"\"\n",
    "    This function generates the html file\n",
    "    Args:\n",
    "    detected_elements_info: Information about the detected elements\n",
    "    file_name: Name of the file\n",
    "    \"\"\"\n",
    "    file_name, extension = file_name.split(\".\")\n",
    "\n",
    "    gen = HtmlGenerator(file_name)\n",
    "\n",
    "    for element_info in detected_elements_info:\n",
    "\n",
    "        if element_info[\"class\"] == \"paragraph\":\n",
    "            gen.insert_paragraph(element_info)\n",
    "\n",
    "        elif element_info[\"class\"] == \"text_box\":\n",
    "            gen.insert_text_box(element_info)\n",
    "\n",
    "        elif element_info[\"class\"] == \"image\":\n",
    "            gen.insert_image(element_info)\n",
    "\n",
    "    gen.create_html_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to get proper coordinate information and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_coordinates(xyxy_tensor, height, width):\n",
    "    \"\"\"\n",
    "    This function gets the normalized coordinates\n",
    "    Args:\n",
    "    xyxy_tensor: Tensor containing the coordinates\n",
    "    height: Height of the image\n",
    "    width: Width of the image\n",
    "    Returns:\n",
    "    coordinates: Normalized coordinates\n",
    "    \"\"\"\n",
    "    x_min = xyxy_tensor[0][0].item() / width\n",
    "    y_min = xyxy_tensor[0][1].item() / height\n",
    "    x_max = xyxy_tensor[0][2].item() / width\n",
    "    y_max = xyxy_tensor[0][3].item() / height\n",
    "\n",
    "    coordinates = [x_min, y_min, x_max, y_max]\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def get_original_coordinates(normalized_coordinates, image_width, image_height):\n",
    "    \"\"\"\n",
    "    This function gets the original coordinates\n",
    "    Args:\n",
    "    normalized_coordinates: Normalized coordinates\n",
    "    image_width: Width of the image\n",
    "    image_height: Height of the image\n",
    "    Returns:\n",
    "    orig_coordinates: Original coordinates\n",
    "    \"\"\"\n",
    "    orig_coordinates = [None] * 4\n",
    "\n",
    "    orig_coordinates[0] = math.floor(normalized_coordinates[0] * image_width)\n",
    "    orig_coordinates[1] = math.floor(normalized_coordinates[1] * image_height)\n",
    "    orig_coordinates[2] = math.ceil(normalized_coordinates[2] * image_width)\n",
    "    orig_coordinates[3] = math.ceil(normalized_coordinates[3] * image_height)\n",
    "\n",
    "    return orig_coordinates\n",
    "\n",
    "\n",
    "def get_coordinates_from_segmentation(result_word):\n",
    "    \"\"\"\n",
    "    This function gets the coordinates from the segmentation\n",
    "    Args:\n",
    "    result_word: Result of the word segmentation\n",
    "    Returns:\n",
    "    words_xyxy: Coordinates of the words\n",
    "    \"\"\"\n",
    "    words_xyxy = []\n",
    "    if result_word != None:\n",
    "        for i in range(len(result_word)):\n",
    "            [[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]] = (\n",
    "                result_word[i]\n",
    "            )\n",
    "            words_xyxy.append([int(x_min), int(y_min), int(x_max), int(y_max)])\n",
    "\n",
    "    return words_xyxy\n",
    "\n",
    "def top_bottom_padding(cropped_text_region):\n",
    "    \"\"\"\n",
    "    This function adds top and bottom padding to the cropped text region\n",
    "    Args:\n",
    "    cropped_text_region: Cropped text region\n",
    "    Returns:\n",
    "    padded_image: Padded image\n",
    "    \"\"\"\n",
    "    h, w = cropped_text_region.shape[:2]\n",
    "    padded_height = int(h * 1.5)\n",
    "    padded_width = w\n",
    "\n",
    "    padded_image = np.ones((padded_height, padded_width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    top_padding = (h * 2 - h) // 2\n",
    "    bottom_padding = top_padding + h\n",
    "\n",
    "    padded_image[top_padding:bottom_padding, :] = cropped_text_region\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes care of all the inference, that is, Layout Detection at first (`res = model(image)[0]`), then line segmentation, word segmentation and finally returning all of them with appropriate coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = {0: \"paragraph\", 1: \"text_box\", 2: \"image\", 3: \"table\"}\n",
    "\n",
    "def run_inference(image_path, file_name, img_src_save_directory):\n",
    "    \"\"\"\n",
    "    This function runs the inference\n",
    "    Args:\n",
    "    image_path: Path of the image\n",
    "    file_name: Name of the file\n",
    "    img_src_save_directory: Directory to save the image\n",
    "    Returns:\n",
    "    region_of_interests: Region of interests\n",
    "    \"\"\"\n",
    "    file_name, extension = file_name.split(\".\")\n",
    "    image = cv2.imread(image_path)\n",
    "    res = model(image)[0]\n",
    "    res.save(f\"reconstruction/image/{file_name}.{extension}\")\n",
    "    region_of_interests = []\n",
    "    for i in range(len(res.boxes)):\n",
    "        info_dict = {\n",
    "            \"class\": None,\n",
    "            \"coordinates\": None,\n",
    "            \"left\": None,\n",
    "            \"top\": None,\n",
    "            \"elem_height\": None,\n",
    "            \"elem_width\": None,\n",
    "            \"img_height\": None,\n",
    "            \"img_width\": None,\n",
    "            \"text\": None,\n",
    "            \"single-line\": False,\n",
    "            \"img_src\": None,\n",
    "            \"font_size\": None,  # Add font size attribute\n",
    "        }\n",
    "        cls = res.boxes[i].cls.item()\n",
    "        img_height, img_width = res.boxes[i].orig_shape\n",
    "        normalized_coordinates = get_normalized_coordinates(\n",
    "            res.boxes[i].xyxy, img_height, img_width\n",
    "        )\n",
    "        if cls == 0:\n",
    "            info_dict[\"class\"] = names[0]\n",
    "        elif cls == 1:\n",
    "            info_dict[\"class\"] = names[1]\n",
    "        elif cls == 2:\n",
    "            info_dict[\"class\"] = names[2]\n",
    "        elif cls == 3:\n",
    "            info_dict[\"class\"] = names[3]\n",
    "        info_dict[\"coordinates\"] = normalized_coordinates\n",
    "        info_dict[\"left\"], info_dict[\"top\"] = (\n",
    "            normalized_coordinates[0] * 100,\n",
    "            normalized_coordinates[1] * 100,\n",
    "        )\n",
    "        info_dict[\"img_height\"], info_dict[\"img_width\"] = img_height, img_width\n",
    "        info_dict[\"elem_width\"] = (\n",
    "            normalized_coordinates[2] - normalized_coordinates[0]\n",
    "        ) * 100\n",
    "        info_dict[\"elem_height\"] = (\n",
    "            normalized_coordinates[3] - normalized_coordinates[1]\n",
    "        ) * 100\n",
    "        if info_dict[\"class\"] == \"paragraph\" or info_dict[\"class\"] == \"text_box\":\n",
    "            x_min, y_min, x_max, y_max = get_original_coordinates(\n",
    "                normalized_coordinates, info_dict[\"img_width\"], info_dict[\"img_height\"]\n",
    "            )\n",
    "            cropped_text_region = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            cropped_text_region = top_bottom_padding(cropped_text_region)\n",
    "            result_line = line_segmentation(cropped_text_region)\n",
    "            line_coordinates = get_coordinates_from_segmentation(result_line)\n",
    "            sorted_line_coordinates = sorted(line_coordinates, key=lambda x: x[1])\n",
    "            text = []\n",
    "            for i in range(len(sorted_line_coordinates)):\n",
    "                cropped_line_region = cropped_text_region[\n",
    "                    sorted_line_coordinates[i][1] : sorted_line_coordinates[i][3],\n",
    "                    sorted_line_coordinates[i][0] : sorted_line_coordinates[i][2],\n",
    "                ]\n",
    "                if len(sorted_line_coordinates) == 1:\n",
    "                    info_dict[\"single-line\"] = True\n",
    "                    info_dict[\"elem_height\"] *= 1.4\n",
    "                if len(cropped_line_region) != 0:\n",
    "                    result_word = word_segmentation(cropped_line_region)\n",
    "                    if result_word != None:\n",
    "                        if len(result_word) != 0:\n",
    "                            sorted_result_word = sorted(\n",
    "                                result_word[0], key=lambda x: x[0]\n",
    "                            )\n",
    "                            if len(sorted_result_word) != 0:\n",
    "                                words = recognize_word(\n",
    "                                    cropped_line_region, [sorted_result_word]\n",
    "                                )\n",
    "                                text += words\n",
    "            text = \"\".join(text)\n",
    "            info_dict[\"text\"] = text\n",
    "            \n",
    "            # Calculate font size based on the size of the text region\n",
    "            font_size = int(info_dict[\"elem_height\"])  # Adjust font size as needed\n",
    "            print(f\"Font size -> {font_size}\")\n",
    "            info_dict[\"font_size\"] = font_size\n",
    "\n",
    "        elif info_dict[\"class\"] == \"image\":\n",
    "            x_min, y_min, x_max, y_max = get_original_coordinates(\n",
    "                normalized_coordinates, info_dict[\"img_width\"], info_dict[\"img_height\"]\n",
    "            )\n",
    "            cropped_image_region = image[y_min:y_max, x_min:x_max]\n",
    "            src = f\"{img_src_save_directory}\\\\{file_name}_{i}.{extension}\"\n",
    "            info_dict[\"img_src\"] = src\n",
    "            cv2.imwrite(\n",
    "                f\"reconstruction/image/{file_name}_{i}.{extension}\",\n",
    "                cropped_image_region,\n",
    "            )\n",
    "        region_of_interests.append(info_dict)\n",
    "    discard_elements = []\n",
    "    for i, element in enumerate(region_of_interests):\n",
    "        bb1 = box(\n",
    "            element[\"coordinates\"][0],\n",
    "            element[\"coordinates\"][1],\n",
    "            element[\"coordinates\"][2],\n",
    "            element[\"coordinates\"][3],\n",
    "        )\n",
    "\n",
    "        for j, other_element in enumerate(region_of_interests):\n",
    "            if j > i:\n",
    "                bb2 = box(\n",
    "                    other_element[\"coordinates\"][0],\n",
    "                    other_element[\"coordinates\"][1],\n",
    "                    other_element[\"coordinates\"][2],\n",
    "                    other_element[\"coordinates\"][3],\n",
    "                )\n",
    "                intersection = bb1.intersection(bb2).area\n",
    "                if bb1.area < bb2.area:\n",
    "                    iou = intersection / bb1.area\n",
    "                    if iou > 0.5:\n",
    "                        if i not in discard_elements:\n",
    "                            discard_elements.append(i)\n",
    "                else:\n",
    "                    iou = intersection / bb2.area\n",
    "                    if iou > 0.5:\n",
    "                        if j not in discard_elements:\n",
    "                            discard_elements.append(j)\n",
    "    items_deleted = 0\n",
    "    for index in discard_elements:\n",
    "        del region_of_interests[index - items_deleted]\n",
    "        items_deleted += 1\n",
    "    return region_of_interests\n",
    "\n",
    "\n",
    "\n",
    "# def run_inference(image_path, file_name, img_src_save_directory):\n",
    "#     \"\"\"\n",
    "#     This function runs the inference\n",
    "#     Args:\n",
    "#     image_path: Path of the image\n",
    "#     file_name: Name of the file\n",
    "#     img_src_save_directory: Directory to save the image\n",
    "#     Returns:\n",
    "#     region_of_interests: Region of interests\n",
    "#     \"\"\"\n",
    "#     file_name, extension = file_name.split(\".\")\n",
    "#     image = cv2.imread(image_path)\n",
    "#     res = model(image)[0]\n",
    "#     res.save(f\"reconstruction/image/{file_name}.{extension}\")\n",
    "#     region_of_interests = []\n",
    "#     for i in range(len(res.boxes)):\n",
    "#         info_dict = {\n",
    "#             \"class\": None,\n",
    "#             \"coordinates\": None,\n",
    "#             \"left\": None,\n",
    "#             \"top\": None,\n",
    "#             \"elem_height\": None,\n",
    "#             \"elem_width\": None,\n",
    "#             \"img_height\": None,\n",
    "#             \"img_width\": None,\n",
    "#             \"text\": None,\n",
    "#             \"single-line\": False,\n",
    "#             \"img_src\": None,\n",
    "#         }\n",
    "#         cls = res.boxes[i].cls.item()\n",
    "#         img_height, img_width = res.boxes[i].orig_shape\n",
    "#         normalized_coordinates = get_normalized_coordinates(\n",
    "#             res.boxes[i].xyxy, img_height, img_width\n",
    "#         )\n",
    "#         if cls == 0:\n",
    "#             info_dict[\"class\"] = names[0]\n",
    "#         elif cls == 1:\n",
    "#             info_dict[\"class\"] = names[1]\n",
    "#         elif cls == 2:\n",
    "#             info_dict[\"class\"] = names[2]\n",
    "#         elif cls == 3:\n",
    "#             info_dict[\"class\"] = names[3]\n",
    "#         info_dict[\"coordinates\"] = normalized_coordinates\n",
    "#         info_dict[\"left\"], info_dict[\"top\"] = (\n",
    "#             normalized_coordinates[0] * 100,\n",
    "#             normalized_coordinates[1] * 100,\n",
    "#         )\n",
    "#         info_dict[\"img_height\"], info_dict[\"img_width\"] = img_height, img_width\n",
    "#         info_dict[\"elem_width\"] = (\n",
    "#             normalized_coordinates[2] - normalized_coordinates[0]\n",
    "#         ) * 100\n",
    "#         info_dict[\"elem_height\"] = (\n",
    "#             normalized_coordinates[3] - normalized_coordinates[1]\n",
    "#         ) * 100\n",
    "#         if info_dict[\"class\"] == \"paragraph\" or info_dict[\"class\"] == \"text_box\":\n",
    "#             x_min, y_min, x_max, y_max = get_original_coordinates(\n",
    "#                 normalized_coordinates, info_dict[\"img_width\"], info_dict[\"img_height\"]\n",
    "#             )\n",
    "#             cropped_text_region = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "#             cropped_text_region = top_bottom_padding(cropped_text_region)\n",
    "#             result_line = line_segmentation(cropped_text_region)\n",
    "#             line_coordinates = get_coordinates_from_segmentation(result_line)\n",
    "#             sorted_line_coordinates = sorted(line_coordinates, key=lambda x: x[1])\n",
    "#             text = []\n",
    "#             for i in range(len(sorted_line_coordinates)):\n",
    "#                 cropped_line_region = cropped_text_region[\n",
    "#                     sorted_line_coordinates[i][1] : sorted_line_coordinates[i][3],\n",
    "#                     sorted_line_coordinates[i][0] : sorted_line_coordinates[i][2],\n",
    "#                 ]\n",
    "#                 if len(sorted_line_coordinates) == 1:\n",
    "#                     info_dict[\"single-line\"] = True\n",
    "#                     info_dict[\"elem_height\"] *= 1.4\n",
    "#                 if len(cropped_line_region) != 0:\n",
    "#                     result_word = word_segmentation(cropped_line_region)\n",
    "#                     if result_word != None:\n",
    "#                         if len(result_word) != 0:\n",
    "#                             sorted_result_word = sorted(\n",
    "#                                 result_word[0], key=lambda x: x[0]\n",
    "#                             )\n",
    "#                             if len(sorted_result_word) != 0:\n",
    "#                                 words = recognize_word(\n",
    "#                                     cropped_line_region, [sorted_result_word]\n",
    "#                                 )\n",
    "#                                 text += words\n",
    "#             text = \"\".join(text)\n",
    "#             info_dict[\"text\"] = text\n",
    "#         elif info_dict[\"class\"] == \"image\":\n",
    "#             x_min, y_min, x_max, y_max = get_original_coordinates(\n",
    "#                 normalized_coordinates, info_dict[\"img_width\"], info_dict[\"img_height\"]\n",
    "#             )\n",
    "#             cropped_image_region = image[y_min:y_max, x_min:x_max]\n",
    "#             src = f\"{img_src_save_directory}\\\\{file_name}_{i}.{extension}\"\n",
    "#             info_dict[\"img_src\"] = src\n",
    "#             cv2.imwrite(\n",
    "#                 f\"reconstruction/image/{file_name}_{i}.{extension}\",\n",
    "#                 cropped_image_region,\n",
    "#             )\n",
    "#         region_of_interests.append(info_dict)\n",
    "#     discard_elements = []\n",
    "#     for i, element in enumerate(region_of_interests):\n",
    "#         bb1 = box(\n",
    "#             element[\"coordinates\"][0],\n",
    "#             element[\"coordinates\"][1],\n",
    "#             element[\"coordinates\"][2],\n",
    "#             element[\"coordinates\"][3],\n",
    "#         )\n",
    "\n",
    "#         for j, other_element in enumerate(region_of_interests):\n",
    "#             if j > i:\n",
    "#                 bb2 = box(\n",
    "#                     other_element[\"coordinates\"][0],\n",
    "#                     other_element[\"coordinates\"][1],\n",
    "#                     other_element[\"coordinates\"][2],\n",
    "#                     other_element[\"coordinates\"][3],\n",
    "#                 )\n",
    "#                 intersection = bb1.intersection(bb2).area\n",
    "#                 if bb1.area < bb2.area:\n",
    "#                     iou = intersection / bb1.area\n",
    "#                     if iou > 0.5:\n",
    "#                         if i not in discard_elements:\n",
    "#                             discard_elements.append(i)\n",
    "#                 else:\n",
    "#                     iou = intersection / bb2.area\n",
    "#                     if iou > 0.5:\n",
    "#                         if j not in discard_elements:\n",
    "#                             discard_elements.append(j)\n",
    "#     items_deleted = 0\n",
    "#     for index in discard_elements:\n",
    "#         del region_of_interests[index - items_deleted]\n",
    "#         items_deleted += 1\n",
    "#     return region_of_interests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a gigantic class, takes care of everything, that is, calling inference and passing it to HTML Geneation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(directory, img_src_save_dir):\n",
    "    \"\"\"\n",
    "    This function reconstructs the image\n",
    "    Args:\n",
    "    directory: Directory containing the images\n",
    "    img_src_save_dir: Directory to save the image\n",
    "    \"\"\"\n",
    "    directory = \"image/\"  # Replace with your test directory path\n",
    "    img_src_save_dir = \"image/\"  # Replace with your image source directory path\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, file_name)):\n",
    "\n",
    "            file_path = directory + \"/\" + file_name\n",
    "\n",
    "            print(\n",
    "                \"----------------------------------------------------------------------------\"\n",
    "            )\n",
    "            print(\"File name:\", file_name)\n",
    "\n",
    "            start_time = time.time()\n",
    "            roi = run_inference(\n",
    "                file_path, file_name, img_src_save_dir\n",
    "            )\n",
    "            print(\n",
    "                \"Execution Time for Layout Prediction and Text Recognition:\",\n",
    "                round(time.time() - start_time, 2),\n",
    "                \"seconds\",\n",
    "            )\n",
    "\n",
    "            start_time = time.time()\n",
    "            print(roi)\n",
    "            generate_html(roi, file_name)\n",
    "            print(\n",
    "                \"Execution Time for Reconstruction:\",\n",
    "                round(time.time() - start_time, 2),\n",
    "                \"seconds\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify this to your need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "File name: Colonialism.png\n",
      "\n",
      "0: 960x832 16 paragraphs, 8 text_boxs, 4228.3ms\n",
      "Speed: 15.2ms preprocess, 4228.3ms inference, 266.8ms postprocess per image at shape (1, 3, 960, 832)\n",
      "Font size -> 11\n",
      "Font size -> 5\n",
      "Font size -> 4\n",
      "Font size -> 3\n",
      "Font size -> 5\n",
      "Font size -> 4\n",
      "Font size -> 3\n",
      "Font size -> 4\n",
      "Font size -> 4\n",
      "Font size -> 6\n",
      "Font size -> 4\n",
      "Font size -> 2\n",
      "Font size -> 3\n",
      "Font size -> 2\n",
      "Font size -> 2\n",
      "Font size -> 3\n",
      "Font size -> 2\n",
      "Font size -> 2\n",
      "Font size -> 3\n",
      "Font size -> 3\n",
      "Font size -> 3\n",
      "Font size -> 1\n",
      "Font size -> 2\n",
      "Font size -> 3\n",
      "Execution Time for Layout Prediction and Text Recognition: 57.36 seconds\n",
      "[{'class': 'paragraph', 'coordinates': [0.10014659226542771, 0.5638624011960804, 0.9012867320667614, 0.6798816909137954], 'left': 10.014659226542772, 'top': 56.38624011960805, 'elem_height': 11.60192897177149, 'elem_width': 80.11401398013336, 'img_height': 936, 'img_width': 792, 'text': 'The fact is that the so-called European civilization - \"Western\" civilization - as it hasbeen shaped by two centuries of bourgeois rule,is incapable of solving the two majorproblems to which its existence has given rise: the problem of the proletariat and thecolonial problem; that Europe is unable to justify itself either before the bar of \"reason\" orbefore the bar of \"conscience\";and that, increasingly, it takes refuge in a hypocrisy whichis all the more odious because it is less and less likely to deceive.', 'single-line': False, 'img_src': None, 'font_size': 11}, {'class': 'paragraph', 'coordinates': [0.10053129870482165, 0.8106189956012954, 0.9001128071486347, 0.8703894329886152], 'left': 10.053129870482165, 'top': 81.06189956012953, 'elem_height': 5.97704373873198, 'elem_width': 79.95815084438131, 'img_height': 936, 'img_width': 792, 'text': 'The colonialists may kill in Indochina, torture in Madagascar, imprison in BlackAfrica, crackdown in the West Indies.Henceforth, the colonized know that they have anadvantage over them.They know that their temporary,\"masters\" are lying', 'single-line': False, 'img_src': None, 'font_size': 5}, {'class': 'paragraph', 'coordinates': [0.09834388771442452, 0.4644031361636952, 0.8939595848622949, 0.5077884380634015], 'left': 9.834388771442452, 'top': 46.44031361636952, 'elem_height': 4.338530189970625, 'elem_width': 79.56156971478704, 'img_height': 936, 'img_width': 792, 'text': 'A civilization that proves incapable of solving the problems it creates is a decadent', 'single-line': False, 'img_src': None, 'font_size': 4}, {'class': 'paragraph', 'coordinates': [0.09608599152227845, 0.5066195430918636, 0.903044960715554, 0.5453426654522235], 'left': 9.608599152227844, 'top': 50.66195430918636, 'elem_height': 3.8723122360359907, 'elem_width': 80.69589691932755, 'img_height': 936, 'img_width': 792, 'text': 'A civilization that chooses to close its eyes to its most crucial problems is a stricken', 'single-line': False, 'img_src': None, 'font_size': 3}, {'class': 'paragraph', 'coordinates': [0.10256438785129124, 0.7544153327615852, 0.8977789830679845, 0.8110211364224426], 'left': 10.256438785129124, 'top': 75.44153327615852, 'elem_height': 5.660580366085732, 'elem_width': 79.52145952166933, 'img_height': 936, 'img_width': 792, 'text': 'but on a world scale, by tens and tens of millions of men who, from the depths of slavery,', 'single-line': False, 'img_src': None, 'font_size': 5}, {'class': 'paragraph', 'coordinates': [0.10101075605912642, 0.8856578077006544, 0.9005447541824495, 0.9279872535640358], 'left': 10.101075605912643, 'top': 88.56578077006544, 'elem_height': 4.232944586338139, 'elem_width': 79.95339981233231, 'img_height': 936, 'img_width': 792, 'text': 'And since I have been asked to speak about colonization and civilization, let us gostraight to the principal lie which is the source of all the others.', 'single-line': False, 'img_src': None, 'font_size': 4}, {'class': 'text_box', 'coordinates': [0.09563455677995777, 0.4163849333412627, 0.5173964066938921, 0.4473289750580095], 'left': 9.563455677995778, 'top': 41.63849333412627, 'elem_height': 3.0944041716746806, 'elem_width': 42.17618499139343, 'img_height': 936, 'img_width': 792, 'text': '', 'single-line': False, 'img_src': None, 'font_size': 3}, {'class': 'paragraph', 'coordinates': [0.09976143307156032, 0.1603582496317024, 0.8952119615342882, 0.20070887834597856], 'left': 9.976143307156033, 'top': 16.03582496317024, 'elem_height': 4.035062871427616, 'elem_width': 79.54505284627278, 'img_height': 936, 'img_width': 792, 'text': 'Translated by Joan Pinkham. This version published by Monthly Review Press: New York and London1972. Originally published as Discours sur le colonialisme by Editions Presence Africaine, 1955.', 'single-line': False, 'img_src': None, 'font_size': 4}, {'class': 'text_box', 'coordinates': [0.380815833505958, 0.11643788753411709, 0.6112351465706873, 0.1474549546201005], 'left': 38.0815833505958, 'top': 11.643788753411709, 'elem_height': 4.342389392037677, 'elem_width': 23.041931306472936, 'img_height': 936, 'img_width': 792, 'text': 'Aime Cesaire', 'single-line': True, 'img_src': None, 'font_size': 4}, {'class': 'text_box', 'coordinates': [0.134360746903853, 0.05185591053758931, 0.859569742222025, 0.10118050045437282], 'left': 13.436074690385299, 'top': 5.185591053758931, 'elem_height': 6.9054425883496915, 'elem_width': 72.5208995318172, 'img_height': 936, 'img_width': 792, 'text': 'Discourse on Colonialism', 'single-line': True, 'img_src': None, 'font_size': 6}, {'class': 'text_box', 'coordinates': [0.4118788748076468, 0.2793222411066039, 0.5837300618489584, 0.3101818704197549], 'left': 41.18788748076468, 'top': 27.932224110660393, 'elem_height': 4.32034810384114, 'elem_width': 17.18511870413116, 'img_height': 936, 'img_width': 792, 'text': 'Contents', 'single-line': True, 'img_src': None, 'font_size': 4}, {'class': 'paragraph', 'coordinates': [0.15786339538265962, 0.8681006798377404, 0.5090028011437618, 0.886616437863081], 'left': 15.786339538265961, 'top': 86.81006798377405, 'elem_height': 2.592206123547678, 'elem_width': 35.113940576110224, 'img_height': 936, 'img_width': 792, 'text': 'Therefore, that their masters are weak', 'single-line': True, 'img_src': None, 'font_size': 2}, {'class': 'paragraph', 'coordinates': [0.10103007037230212, 0.20943118364383012, 0.893308157872672, 0.2483424325274606], 'left': 10.103007037230212, 'top': 20.94311836438301, 'elem_height': 3.8911248883630485, 'elem_width': 79.22780875003698, 'img_height': 936, 'img_width': 792, 'text': 'COPYRIGHT: From a Counter-Racist perspective, this is nothing other than a mechanism employed byWhite Supremacists (Racists) that has been designed to control access to information by non-White people.', 'single-line': False, 'img_src': None, 'font_size': 3}, {'class': 'paragraph', 'coordinates': [0.15865066798046382, 0.6786171024681157, 0.37237537268436316, 0.6970798459827391], 'left': 15.865066798046382, 'top': 67.86171024681157, 'elem_height': 2.5847840920472764, 'elem_width': 21.372470470389935, 'img_height': 936, 'img_width': 792, 'text': 'Europe is indefensible', 'single-line': True, 'img_src': None, 'font_size': 2}, {'class': 'paragraph', 'coordinates': [0.1473423350941051, 0.5443946642753406, 0.8554111056857638, 0.5638790945721488], 'left': 14.73423350941051, 'top': 54.43946642753406, 'elem_height': 2.727820241553154, 'elem_width': 70.80687705916587, 'img_height': 936, 'img_width': 792, 'text': '', 'single-line': True, 'img_src': None, 'font_size': 2}, {'class': 'paragraph', 'coordinates': [0.15634942295575383, 0.9253425272102029, 0.4258430172698666, 0.9470939310187967], 'left': 15.634942295575382, 'top': 92.5342527210203, 'elem_height': 3.045196533203125, 'elem_width': 26.94935943141128, 'img_height': 936, 'img_width': 792, 'text': 'Colonization and civilization?', 'single-line': True, 'img_src': None, 'font_size': 3}, {'class': 'paragraph', 'coordinates': [0.1750082921500158, 0.7339830317048945, 0.7441651315400095, 0.7541640844100561], 'left': 17.50082921500158, 'top': 73.39830317048946, 'elem_height': 2.82534737872262, 'elem_width': 56.91568393899937, 'img_height': 936, 'img_width': 792, 'text': '/hat is serious is that \"Europe\" is morally,spiritually indefensible', 'single-line': True, 'img_src': None, 'font_size': 2}, {'class': 'paragraph', 'coordinates': [0.1564412068839025, 0.7159562070145566, 0.40750322438249686, 0.7350563636192908], 'left': 15.64412068839025, 'top': 71.59562070145566, 'elem_height': 2.674021924662786, 'elem_width': 25.106201749859437, 'img_height': 936, 'img_width': 792, 'text': 'That in itself is not serious.', 'single-line': True, 'img_src': None, 'font_size': 2}, {'class': 'text_box', 'coordinates': [0.09659914536909624, 0.3573695777827858, 0.4540308942698469, 0.3812175978962173], 'left': 9.659914536909623, 'top': 35.73695777827858, 'elem_height': 3.338722815880411, 'elem_width': 35.74317489007506, 'img_height': 936, 'img_width': 792, 'text': 'AN INTERVIEW WITH AIME CESAIRE', 'single-line': True, 'img_src': None, 'font_size': 3}, {'class': 'paragraph', 'coordinates': [0.15251979442557903, 0.6952373798076923, 0.8431048152422664, 0.7197775555472089], 'left': 15.251979442557904, 'top': 69.52373798076923, 'elem_height': 3.4356246035323257, 'elem_width': 69.05850208166873, 'img_height': 936, 'img_width': 792, 'text': 'Apparently that is what the American strategists are whispering to each other', 'single-line': True, 'img_src': None, 'font_size': 3}, {'class': 'text_box', 'coordinates': [0.4801009207060843, 0.9762580415122529, 0.5215955406728418, 0.9957443628555689], 'left': 48.01009207060843, 'top': 97.6258041512253, 'elem_height': 1.948632134331596, 'elem_width': 4.149461996675746, 'img_height': 936, 'img_width': 792, 'text': '', 'single-line': False, 'img_src': None, 'font_size': 1}, {'class': 'text_box', 'coordinates': [0.09949815152871488, 0.3262777083959335, 0.902480231391059, 0.3532874278533153], 'left': 9.949815152871489, 'top': 32.62777083959335, 'elem_height': 3.7813607240334495, 'elem_width': 80.29820798623442, 'img_height': 936, 'img_width': 792, 'text': '', 'single-line': True, 'img_src': None, 'font_size': 3}]\n",
      "Execution Time for Reconstruction: 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "test_image_directory = \"image/\"\n",
    "img_src_save_dir = \"image/\"\n",
    "reconstruct(test_image_directory, img_src_save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbocr-env-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
